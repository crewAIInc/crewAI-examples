SERPER_API_KEY="your_serper_api_key_here" # https://serper.dev/ (free tier)
BROWSERLESS_API_KEY="your_browserless_api_key_here" # https://www.browserless.io/ (free tier)

# Ollama configuration - required for LLM functionality
# 1. Start Ollama: ollama serve
# 2. Pull a model: ollama pull llama3.2
# 3. Available models: llama3.2, llama3.1, mistral, codellama, etc.
OLLAMA_MODEL="llama3.2"
OLLAMA_BASE_URL="http://localhost:11434"
